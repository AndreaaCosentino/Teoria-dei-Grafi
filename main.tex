\documentclass[12pt]{report}
\usepackage{mioStile}

\pgfplotsset{compat = 1.18}

\title{Teoria dei grafi}
\author{Andrea Cosentino}
\sectionfont{\fontsize{12}{15}\selectfont}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\setlength{\columnsep}{0.8cm}
\setlength{\columnseprule}{0.2pt}
\twocolumn

\chapter{Prima lezione}
\noindent
Un grafo $G = (V,E)$ è una struttura algebrica dove $V$ è l'insieme finito di vertici e $E$ è l'insieme finito di archi. Inoltre, vale che $E = [V]^2$. Dato un insieme $S$ e un qualunque intero $k \in \{2,\dots,|S|\}$, diciamo che $[S]^k$ è la collezione di tutti i sottoinsieme di $S$ formati da $k$ elementi. Per esempio, dato l'insieme $S = \{1,2,3\}$ l'insieme $[S]^2$ contiene $\{\{1,2\}, \{1,3\},\{2,3\}\}$. 

\begin{exmp}
    Un esempio di grafo $G = (V,E)$ è $V = \{1,2,3\}$ e $E = \{\{1,2\},\{1,3\}\}$.
    
\vspace{10px}
\begin{center}
\begin{tikzpicture}{}
    \node[] (A) {$1$};
    \node[below left= 2cm and 1cm of A] (B){$2$};
    \node[below right= 2cm and 1cm of A] (C){$3$};

    \draw[] (A) -- (B);
    \draw[] (A) -- (C);
\end{tikzpicture}
\end{center}
\end{exmp}

\noindent
Notare che ci concentriamo su grafi con archi non orientati.

La nomenclatura che utilizzeremo per indicare dei vertici generici è $i,j,u,v$, mentre per indicare degli archi generici è $(i,j)$. Dire $(i,j)$ implicherebbe un ordine, per evitare di scrivere $\{i,j\}$ useremo $(i,j)$ senza implicare che l'arco sia orientato.

Il numero di nodi del grafo è detto \textbf{ordine}, e corrisponde a $|V|$. Un grafo di ordine $0$ è detto grafo \textbf{vuoto}, mentre un grafo di ordine $\leq 1$ è detto grafo \textbf{banale}. Esistono solamente due grafi di ordine $2$:

\disegna{ 
    \node[]  (A1) at (-3.5,0) {$A)$};
    \node[nodo] (A) at (-3,0){};
    \node[nodo] (B) at (-1,0){};

    \node[]  (A2) at (-3.5,-2) {$B)$};
    \node[nodo] (C) at (-3,-2){};
    \node[nodo] (D) at (-1,-2){};
    \draw[] (C) -- (D);
}

\noindent
Dato un arco $e = (i,j) \in E$ diciamo che $i,j$ sono vertici incidenti all'arco $e$. Due vertici $i,j$ con $i \neq j$ tali che $(i,j) \in E$ sono detti vertici \textbf{adiacenti} in $G(V,E)$.  Se $E \equiv [V]^2$ diciamo che il grafo è \textbf{completo} oppure che è una \textbf{clique} (o cricca in italiano). Un grafo completo su $n$ vertici è chiamato $K_n$. Alcuni esempi di grafi completi sono

\disegna{

    \node[]  (A) at (2,0) {$K_2$};
    \node[nodo] (A1) at (-2,0){};
    \node[nodo] (A2) at (0,0){};
    \draw[] (A1) -- (A2);

    \node[]  (B) at (2,-3) {$K_3$};
    \node[nodo] (B1) at (-1,-2){};
    \node[nodo] (B2) at (-2,-4){};
    \node[nodo] (B3) at (0,-4){};
    \draw[] (B1) -- (B2);
    \draw[] (B2) -- (B3);
    \draw[] (B1) -- (B3);

    \node[]  (C) at (2,-7) {$K_4$};
    \node[nodo] (C1) at (-2.5,-6){};
    \node[nodo] (C2) at (-2.5,-8){};
    \node[nodo] (C3) at (0.5,-6){};
    \node[nodo] (C4) at (0.5,-8){};
    \draw[] (C1) -- (C2);
    \draw[] (C2) -- (C3);
    \draw[] (C1) -- (C3);
    \draw[] (C1) -- (C4);
    \draw[] (C3) -- (C4);
    \draw[] (C2) -- (C4);
}

\noindent 
Un grafo completo su $n$ vertici ha un numero di archi pari a 
$$\binom{n}{2} = \frac{(n)(n-1)}{2}$$
I grafi che consideriamo sono non orientati e \textbf{semplici}. Un grafo è semplice  se non ha loops (o cappi)

\disegna{
 \node[nodo](A){};
 \node at (1,0) (here){};
 \draw[->,>= stealth]  (A) edge [out=90,in=30,distance=10mm]   (A);
}

\noindent 
e non ha archi multipli, ovvero tra due nodi o c'è un arco non ce n'è neanche io. Quindi la situazione in figura non è ammessa.

\disegna{
 \node[nodo](A){};
 \node[nodo, right =of A] (B){};
 \draw[>= stealth]  (A) edge [out=60,in=150,distance=3.5mm]   (B);
 \draw[>= stealth]  (B) edge [out=-150,in=-60,distance=5mm]   (A);
}

\noindent 
Il sotto-grafo di un grafo $G = (V,E)$ è $G' =(V',E')$ tale che $V' \subseteq V$ e $E' \subseteq E \and [V']^2$. Nella seconda condizione imponiamo che se vogliamo avere l'arco $(i,j)$ nel grafo, allora $i,j \in V'$. Senza questa condizione non otterremmo un grafo. 

\begin{exmp}
    Dato il grafo 
    \disegna{
    \node[nodo] (C1) at (-2.5,-6){};
    \node[left=0.15cm] at (C1.east) {$1$}; 
    \node[nodo] (C2) at (-2.5,-8){};
    \node[left=0.15cm] at (C2.east) {$3$}; 
    \node[nodo] (C3) at (0.5,-6){};
    \node[right=0.15cm] at (C3.west) {$2$}; 
    \node[nodo] (C4) at (0.5,-8){};
    \node[right=0.15cm] at (C4.west) {$4$}; 
    \draw[] (C1) -- (C2);
    \draw[] (C1) -- (C3);
    \draw[] (C3) -- (C4);
    \draw[] (C2) -- (C4);
    }
    Se la seconda condizione fosse solamente $E' \subseteq E$ potremmo scegliere $V' = \{1,2\}$ ed $E' = \{(1,2), (2,3)\}$, ma siccome $3$ non è un nodo, il risultato non è un grafo.
    Un esempio di sotto-grafo è $V' = \{1,2,3,4\}$, $E' = \{(3,4)\}$

    \disegna{
    \node[nodo] (C1) at (-2.5,-6){};
    \node[left=0.15cm] at (C1.east) {$1$}; 
    \node[nodo] (C2) at (-2.5,-8){};
    \node[left=0.15cm] at (C2.east) {$3$}; 
    \node[nodo] (C3) at (0.5,-6){};
    \node[right=0.15cm] at (C3.west) {$2$}; 
    \node[nodo] (C4) at (0.5,-8){};
    \node[right=0.15cm] at (C4.west) {$4$}; 
    \draw[] (C2) -- (C4);
    }

    \noindent 
\end{exmp}

\noindent
Dato $V' \subseteq V$ il sotto-grafo $G'$ \textbf{indotto} da $V'$ è $G'(V',E')$ con $E' = E \and [V']^2$. Ovvero, se seleziono i vertici seleziono anche gli archi su cui sono incidenti. Dato l'insieme di vertici $V'$ c'è solo un sotto-grafo indotto.


Dato il grafo $G(V,E)$ il vicinato di $N(v)$ di $v \in v$ in $G$ è 

$$N(v) = \{j \in V: (v,j) \in E\}$$
Cioè tutti i nodi connessi a $v$ con un arco.

\begin{exmp}
Dato il grafo 
    \disegna{
    \node[nodo] (C1) at (-2.5,-6){};
    \node[left=0.15cm] at (C1.east) {$u$}; 
    \node[nodo] (C2) at (-2.5,-8){};
    \node[left=0.15cm] at (C2.east) {$v'$}; 
    \node[nodo] (C3) at (0.5,-6){};
    \node[above right=0.075cm] at (C3.north east) {$v$}; 
    \node[nodo] (C5) at (2.5,-6){};
    \node[nodo] (C4) at (0.5,-8){};
    \node[right=0.15cm] at (C4.west) {$\omega$}; 
    \draw[] (C1) -- (C2);
    \draw[] (C1) -- (C3);
    \draw[] (C3) -- (C4);
    \draw[] (C2) -- (C4);
    \draw[] (C5) -- (C3);
    \draw[] (C4) -- (C5);
    }
    Il vicinato di $v$ è $N(v) = V \backslash \{v\}$ mentre il vicinato di $v'$ è $N(v') = \{u,v,\omega\}$.
\end{exmp}

\noindent
Il grado di $v$ in $G$ è $d(v) = |N(v)|$. Se $v$ ha $d(v) = 0$ in $G$ allora si dice \textbf{isolato}.

\disegna{
   \node[]  (B) at (2,-4) {$ISOLATO$};
   \node[nodo] (I) at (2,-3){};
    \node[nodo] (B1) at (-1,-2){};
    \node[nodo] (B2) at (-2,-4){};
    \node[nodo] (B3) at (0,-4){};
    \draw[] (B1) -- (B2);
    \draw[] (B2) -- (B3);
    \draw[] (B1) -- (B3);
    \draw[->,>= stealth]  (B) edge [out=60,in=-60,distance=10mm]   (I);
}

\noindent 
Definiamo il grado minimo come $$\delta(G) = \min {d(v): v \in V}$$ e il grado massimo $$\Delta(G) = \max \{d(v) : v \in V\}$$ Se $\Delta(G) = \delta(G) = k$ allora $G$ è $k$-regolare.

\begin{exmp}
    Il seguente grafo è $2$-regolare
    \disegna{
    \node[nodo] (C1) at (-2.5,-6){};
    \node[nodo] (C2) at (-2.5,-8){};
    \node[nodo] (C3) at (0.5,-6){}; 
    \node[nodo] (C4) at (0.5,-8){};
    \node[nodo] (C5) at (-1,-5){};
    \node[nodo] (C6) at (-1.75,-9){};
    \draw[] (C1) -- (C2);
    \draw[] (C1) -- (C5);
    \draw[] (C5) -- (C3);
    \draw[] (C3) -- (C4);
    \draw[] (C2) -- (C6);
    \draw[] (C4) -- (C6);
    }
\end{exmp}

\noindent 
Il grado medio è
$$D(G) = \frac{1}{|V|} \sum_{v \in V} d(v)$$
Vale che $\delta(G) \leq D(G) \leq \Delta(G)$. La \textbf{densità} è invece definita come 

$$\varepsilon(G) = \frac{|E|}{|V|}$$
La densità ci dice quanti archi ha ,in media, ciascun vertice. Assomiglia al grado medio ma in quest'ultimo contiamo due volte ogni arco. Infatti vale che 

$$|E| = \frac{1}{2} \sum_{v \in V} d(v)$$
$$= \frac{1}{2} D(G) |V|$$
e quindi

$$\varepsilon(G) = \frac{|E|}{|V|}  = \frac{1}{2} D(G) $$

\begin{fatto}
In ogni grafo il numero di vertici di grado dispari è pari.
\end{fatto}

\begin{dimo}
    Cominciamo con l'osservare che $|E|$  è un numero intero, e siccome vale che  $|E| = \frac{1}{2} \sum_{v \in V}$ $d(v)$ allora anche $\frac{1}{2} \sum_{v \in V} d(v)$ è intero. Il valore $\sum_{v \in V} d(v)$ deve essere per forza pari, dato che la sua metà è intera. Dividiamo la sommatoria in due sommatorie:
\begin{align*}
\sum_{v \in V:\, d(v) \; \text{è pari}} d(v)  \\ + \sum_{v \in V:\, d(v) \; \text{è dispari}} d(v)
    \end{align*}
    La sommatoria pari ha come risultato sicuramente un numero pari. Questo vuol dire che, se come risultato finale vogliamo un numero pari, anche la sommatoria dispari deve risultare pari. Ciò è possibile se e solo se il numero di elementi è pari. Infatti, sommando un numero pari di numero dispari otteniamo un numero pari. Quindi il numero di vertici di grado dispari è pari.
\end{dimo}

\noindent 
Ci poniamo adesso la domanda se la densità può scendere sotto il grado minimo. Vediamolo prima con un esempio

\begin{exmp}
    Il seguente grafo 
    \disegna{
    \node[nodo] (C) at (-3,-2){};
    \node[nodo] (D) at (-1,-2){};
    \draw[] (C) -- (D);
    }

    \noindent 
    Ha $\delta(G) = 1$ e $\varepsilon(G) = \frac{1}{2}$, quindi $\delta(G) > \varepsilon(G)$
\end{exmp}

\begin{fatto}
    $\forall G$ con almeno un arco, ha un sotto-grafo indotto $H$ tale che 
    $$\delta(H) > \varepsilon(H) \geq \varepsilon(G) $$
\end{fatto}

\begin{dimo}
    Consideriamo una sequenza di grafi

    $$G = G_0, G_1, G_2, \dots$$
    Dove $G_i = (V_i,E_i)$ e $V_0 \supseteq V_1 \supseteq V_2$, con $G_i$ grafo indotto da $V_i$. Se $V_0(=V)$ ha $v_0$ tale che $d(v_0) \leq \varepsilon(G_0)$ creiamo $V_1 = V_0 \backslash \{v_0\}$. Notiamo che se non esiste $v_0$ che rispetta la condizione, allora 

    $$\forall v \in V d(v) > \varepsilon(G_0)$$
    e quindi $d(G_0) > \varepsilon(G_0)$. In questo caso avremmo già dimostrato il teorema con $H = G$.
    
    Consideriamo adesso $G_1$ indotto da $V_1$ (ricordiamo che $V_1 = V_0 \backslash v$). Iteriamo svolgendo la stessa operazione di prima fino a quando $V_i$ è tale che $\forall v \in V_i \, d(v) > \varepsilon(G_i)$. Notiamo che ci fermeremo prima di svuotare il grafo, infatti arriveremo al caso base 

        \disegna{
    \node[nodo] (C) at (-3,-2){};
    \node[nodo] (D) at (-1,-2){};
    \draw[] (C) -- (D);
    }

    \noindent
    dove sappiamo che vale $\delta(G) > \varepsilon(G)$. Se $G_{i+1}$ viene creato, allora

    $$\varepsilon(G_{i+1}) = \frac{|E_{i+1}|}{|V_{i+1}|}$$
    $$=  \frac{|E_i - d(v_i)|}{|V_i - 1|} \geq  \frac{|E_i - \varepsilon(G_i)|}{|V_i - 1|} $$
    Dove la disuguaglianza vale per la condizione con cui costruiamo il sotto-grafo. 
    $$= \frac{|E_i| - \frac{|E_i|}{|V_i|}}{|V_i - 1} =  \frac{|E_i| |V_i| - |E_i|}{|V_i|(|V_i - 1|)}$$
    dove abbiamo portato a fattore comune il numeratore.
    $$= \frac{|E_i| (|V_i| - 1)}{|V_i|(|V_i - 1|)} = \varepsilon(G_i)$$
    Quindi quando ci fermiamo avremo $G_k$ tale che $$\delta(G_k) > \varepsilon (G_k) \geq \varepsilon(G_0) $$

    
\end{dimo}

\chapter{Seconda lezione}

\noindent
Un \textbf{cammino} di lunghezza $k \geq 0$ in $G = (V,E)$ è un sotto-grafo $P_k$ con $k$ archi e $k+1$ vertici distinti tale che $e_i = (v_{i-1},v_i)$. Indichiamo gli archi con $e_1 \dots e_k$ e i nodi con $v_0,\dots,v_k$.

\disegna{
    \node[cloud,draw,minimum width = 5cm,
    minimum height = 4cm] {};
    \node[nodo] (A) at (1,1){}; 
    \node[] at(1,1.3) {$v_0$};
    \node[nodo] (B) at (1.5,0){}; 
    \node[nodo] (C) at (0.8,-1){}; 
    \node[nodo] (D) at (0,-0.6){}; 
    \node[nodo] (E) at (-2,-0.3){};
    \node[] at(-2,0) {$v_k$};
    \draw[] (A) -- (B) node[above,midway,sloped]{$e_1$};
    \draw[] (B) -- (C)  node[below right,midway]{$e_2$};;
    \draw[] (C) -- (D);
    \draw[] (D) -- (E) node[above,midway]{$e_k$};
}

\noindent 
Usiamo la nuvoletta quando non ci interessa la struttura del grafo. Evidenziamo solo una certa parte.
Nel caso in cui $P_0$ non abbiamo archi nel cammino ma un singolo vertice.

Un \textbf{ciclo} $C_k$ di lunghezza $k \geq 3$ è formato da un cammino $P_{k-1}$ che può essere esteso in $G$ includendo l'arco $(v_{k-1},v_0)$.


\disegna{
    \node[cloud,draw,minimum width = 5cm,
    minimum height = 4cm] {};
    \node[nodo] (A) at (1,1){}; 
    \node[] at(1,1.3) {$v_0$};
    \node[nodo] (B) at (1.5,0){}; 
    \node[nodo] (C) at (0.8,-1){}; 
    \node[nodo] (D) at (0,-0.6){}; 
    \node[nodo] (E) at (-2,-0.3){};
    \node[] at(-2,-0.6) {$v_{k-1}$};
    \draw[] (A) -- (B) node[above,midway,sloped]{$e_1$};
    \draw[] (B) -- (C)  node[below right,midway]{$e_2$};;
    \draw[] (C) -- (D);
    \draw[] (D) -- (E) node[above,near start]{$e_{k-1}$};
    \draw[color= red] (E) -- (A) node[above,midway,sloped,color = white] {$(v_{k-1},v_0)$};
}

\noindent 
In un grafo $G$, il \textbf{calibro} $g(G)$ è la lunghezza del ciclo più breve. La \textbf{circonferenza} è la lunghezza del ciclo più lungo. 

\begin{fatto}
    $\forall \; G$ con $\delta(G) > 2$ contiene un cammino di lunghezza $\delta(G)$ e un ciclo di lunghezza almeno $\delta(G) + 1$.
\end{fatto}

\begin{dimo}
    Prendiamo il cammino più lungo del grafo, $P_k$. Allora tutti i vicini di $P_k$ fanno parte del cammino, altrimenti potrei aggiungerli e allungarlo, $P_k$ non sarebbe il più lungo. Quindi il cammino $P_k$ è almeno lungo $|N(v_k)|$, dove $v_k$ è l'ultimo nodo del cammino. Siccome per ipotesi $|N(v_k)| \geq \delta(G)$ allora esiste un cammino di lunghezza  $\delta(G)$.
    Consideriamo ora il primo vertice che è un vicino di $v_k$.

    \disegna{
    \node[cloud,draw,minimum width = 5cm,
    minimum height = 4cm] {};
    \node[nodo] (A) at (1,1){}; 
    \node[] at(1,1.3) {$v_0$};
    \node[nodo, color = blue] (B) at (1.5,0){}; 
    \node[nodo] (C) at (0.8,-1){}; 
    \node[] at(1.8,0) {$v_i$};
    \node[nodo] (D) at (0,-0.6){}; 
    \node[nodo] (E) at (-2,-0.3){};
    \node[] at(-2,-0.6) {$v_{k}$};
    \draw[color = red] (A) -- (B);
    \draw[color = red] (B) -- (C);
    \draw[color = red] (C) -- (D);
    \draw[color = red] (D) -- (E);
    \draw[] (E) -- (B);
    \draw[] (E) edge [out=-60,in=-1200,distance=5mm] (C);
}
In rosso è evidenziato il cammino $P_k$ e in blu il primo vertice che è vicino di $v_k$. Se consideriamo il cammino in rosso da $v_i$ fino a $v_K$ e aggiungiamo $(v_k,v_i)$ troviamo un ciclo, ciò vale sempre per il fatto $\delta(G) \geq 2$. Il ciclo $C$ è lungo almeno $N(v_k) + 1 \geq \delta(G) + 1$.
    
\end{dimo}

\noindent
Dato $G = (V,E)$ $\forall i,j \in V \exists d(i,j)$ se $i,j$ sono connessi in $G$ da almeno $1$ cammino allora $d(i,j)$ è la lunghezza del cammino più breve, altrimenti è $\infty$. 

\begin{exmp}
Dato il grafo
\disegna{
     \node[cloud,draw,minimum width = 2.5cm,
    minimum height = 4cm] at(-2,0) {};
    \node[cloud,draw,minimum width = 2.8cm,
    minimum height = 4cm] at(2,0) {};

    \node[nodo] at(-1.8,0.3){};
    \node[nodo] at(2.3,-0.5){};
    \node[] at(-1.8,0.7) {$i$};
    \node[] at(2.3,-0.1) {$j$};
 }
 La distanza tra $i,j$ è $d(i,j) = \infty$.
\end{exmp}

\noindent
Il \textbf{diametro} è definito come

$$diam(G) = \max_{i,j \in V} d(i,j) =  \max_{i \in V}  \max_{j \in V} d(i,j) $$
e il raggio 

$$rad(G) = \min_{i\in V} \max_{j \in V} d(i,j)$$
Il raggio lo possiamo vedere come il punto "più centrale". Sia $x$ questo punto centrale, vale che $\forall v \in V d(x,v) \leq rad(G)$. Inoltre  $rad(G) \leq diam(G)$ e questo è ovvio dato che il diametro è una massimizzazione del massimo, mentre il raggio è una minimizzazione del massimo.
Possiamo anche dire che $diam(G) \leq 2 rad(g)$, dato che 
$$\forall u,v \in V d(u,v) \leq d(u,x) + d(x,v)$$
$$\leq rad(G) + rad(G) = 2 rad(G)$$

\begin{fatto}
    $\forall G$ che ha almeno un ciclo soddisfa

    $$g(G) \leq 2 diam(G) + 1$$
\end{fatto}

\noindent
\begin{dimo}
    Consideriamo il grafo
    \disegna{
    \node[cloud,draw,minimum width = 5cm,
    minimum height = 4cm] {};
    \node[nodo] (A) at (1,1){}; 
    \node[] at(1,1.3) {$x$};
    \node[nodo] (B) at (1.5,0){}; 
    \node[nodo] (C) at (0.8,-1){}; 
    \node[nodo] (D) at (0,-0.6){}; 
    \node[nodo] (E) at (-2,-0.3){};
    \node[nodo] (F) at (-1.4,0){};
    \node[nodo] (G) at (0,0.2){};
    \node[nodo] (H) at (0.2,1.2){};
    \node[] at(-2,-0.6) {$y$};
    \draw[color = red] (A) -- (B);
    \draw[color = red] (B) -- (C);
    \draw[color = red] (C) -- (D);
    \draw[color = red] (D) -- (E);
    \draw[color = blue] (E) -- (F);
    \draw[color = blue] (F) -- (G);
    \draw[color = blue] (G) -- (H);
    \draw[color = blue] (H) -- (A);
}
dove il ciclo $C$ è il più corto, con lunghezza $g(G)$. I due vertici $x,y$ sono vertici opposti, cioè tagliano il ciclo in due parti il più possibile uguali. Chiamiamo il percorso in rosso $p_1$ e il percorso in blu $p_2$. Assumiamo per assurdo che $g(G) \geq 2 diam(G) + 2$. Allora $p_1,p_2$ sono lunghi ciascuno almeno $diam(G) + 1$. Però $d(x,y) \leq diam(G)$ per la definizione stessa di diametro. Non tutti gli archi di $P$ (cioè del percorso più breve) stanno su $C$, altrimenti il ciclo avrebbe lunghezza $2diam(G) + 1$. Quindi, possiamo costruire un ciclo più piccolo, prendendo gli archi che non stanno né su $P_1$ né su $P_2$.

 \disegna{
    \node[cloud,draw,minimum width = 5cm,
    minimum height = 4cm] {};
    \node[nodo] (A) at (1,1){}; 
    \node[] at(1,1.3) {$x$};
    \node[nodo] (B) at (1.5,0){}; 
    \node[nodo] (C) at (0.8,-1){}; 
    \node[nodo] (D) at (0,-0.6){}; 
    \node[nodo] (E) at (-2,-0.3){};
    \node[nodo] (F) at (-1.4,0){};
    \node[nodo] (G) at (0,0.2){};
    \node[nodo] (H) at (0.2,1.2){};
    \node[] at(-2,-0.6) {$y$};
    \draw[color = red] (A) -- (B);
    \draw[color = orange] (B) -- (C);
    \draw[color = orange] (C) -- (D);
    \draw[color = orange] (D) -- (E);
    \draw[color = blue] (E) -- (F);
    \draw[color = blue] (F) -- (G);
    \draw[color = blue] (G) -- (H);
    \draw[color = blue] (H) -- (A);
    \draw[color = orange, dashed] (E) -- (B);
}

\noindent 
Il ciclo in arancione è più piccolo di $C$, quindi deve per forza valere che $g(G) \leq 2 diam(G) + 1$.
\end{dimo}

\section{Connettività di un grafo}
Un grafo è \textbf{sconnesso} se $\exists i,j \in V$ $|\; d(i,j) = \infty$. Una \textbf{componente} di un grafo è un qualunque insieme massimale di vertici connessi. Se un grafo è connesso il componente è il grafo stesso. $G$ è $k$-connesso se $|V| > k$ e $\forall X \subset V$ con $|X| < k$ il sotto-grafo indotto $V \backslash X$ è connesso.  Se un grafo è $k$-connesso non possiamo sconnettere il grafo rimuovendo al più $k-1$ vertici. Tutti i grafi sono $0$-connessi. Se $G$ è connesso è anche $1$-connesso, tranne il caso $K_1$ (cricca di un elemento) perché non rispetta la condizione $|V| > 1$. Il massimo intero $k$ tale che $G$ è k-connesso è detta \textbf{connettività} di $G$, che denotiamo con $K(G)$. Vale che $K(K_n) = n-1$.

\begin{exmp}
    Nel caso di $K_4$
    \disegna{
        \node[nodo] (C1) at (-2.5,-6){};
    \node[nodo] (C2) at (-2.5,-8){};
    \node[nodo] (C3) at (0.5,-6){};
    \node[nodo] (C4) at (0.5,-8){};
    \draw[] (C1) -- (C2);
    \draw[] (C2) -- (C3);
    \draw[] (C1) -- (C3);
    \draw[] (C1) -- (C4);
    \draw[] (C3) -- (C4);
    \draw[] (C2) -- (C4);
    }
    il numero di nodi che possiamo rimuovere è $3$.
\end{exmp}

\begin{teo}
    Se $G \notin \{k_0,k_1\}$ (ovvero $G$ non è un grafo banale), allora $K(G) \leq F \leq \delta(G)$ dove $k$ è qualsiasi insieme minimo di archi la cui rimozione sconnette il grafo.
\end{teo}

\begin{dimo}
    La disequazione $F \leq \delta(G)$ è banale. Infatti se sconnetto tutti gli archi attorno a un nodo ho sconnesso il grafo. Concentriamoci su $K(G) \leq F$ e distinguiamo due casi:

    \begin{itemize}
        \item $G$ ha un vertice $v$ che non è incidente a $F$.
    \end{itemize}
                    \disegna{
     \node[cloud,draw,minimum width = 2.5cm,
    minimum height = 4cm] at(-2,0) {};
    \node[cloud,draw,minimum width = 2.8cm,
    minimum height = 4cm] at(2,0) {};

    \node[nodo] (A) at(-1.6,0.9){};
    \node[nodo] (A1) at(-1.55,0.3){};
    \node[nodo] (A2) at(-1.65,-0.3){};
    \node[nodo] (A3) at(-1.6,-0.9){};
    \node[nodo] (v) at(-2.5,0){};
    \node[] at (-2.5,0.3){$v$};
    \node[nodo] (B) at(1.6,0.9){};
    \node[nodo] (B1) at(1.65,0.3){};
    \node[nodo] (B3) at(1.60,-0.9){};
    \draw[] (A)--(B1);
    \draw[] (A1)--(B);
    \draw[] (A2) -- (B3);
    \draw[] (A3) -- (B3);
    \draw (-1.5,0) ellipse (0.5cm and 2cm);
    \draw (0,0) ellipse (0.5cm and 1.5cm);
    \node[] (VC) at (-0.5,-2){$V_c$};
    \node[] (F) at (0,0){$F$};
    \node[] (C) at (-3,-2){$C$};
    \draw[->,>= stealth]  (VC) edge [out=-140,in=-60,distance=7mm]   (-1,-1.85);
     \draw[->,>= stealth]  (C) edge [out=80,in=--150,distance=7mm]   (-2.8,-1.5);
    }

    \noindent 

    dove $C$ è la componente del grafo che ottengo quando rimuovo $F$ e $V_c$ è l'insieme dei nodi connessi agli archi in $F$. Siccome rimuovendo $V_c$ sconnetto il grafo allora $K(G) \leq |V_c| \leq |F|$ 
    \begin{itemize}
        \item $G$ è tale che tutti i vertici sono incidenti con qualche arco in $F$.
    \end{itemize}
    \disegna{
     \node[nodo] (A1) at(-1.55,0.3){};
     \node[] at (-1.55,0.6){$v$};
    \node[nodo] (A2) at(-1.65,-0.3){};
    \node[nodo] (A3) at(-1.6,-0.9){};
    \node[nodo] (B) at(1.6,0.9){};
    \node[nodo] (B1) at(1.65,0.3){};
    \node[nodo] (B3) at(1.60,-0.9){};
    \draw[] (A1) -- (B1);
    \draw[] (A2) -- (B);
    \draw[] (A3) -- (B3);
    \draw[>= stealth]  (A1) edge [out=120,in=-120,distance=7mm]   (A3);
    \draw[>= stealth]  (B3) edge [out=60,in=-60,distance=7mm]   (B);
    \draw[] (A1) -- (A2);
    \draw[] (A3) -- (A2);
    \draw[] (B) -- (B1);
    \draw[] (B1) -- (B3);
    \draw (0,0) ellipse (0.5cm and 1.5cm);
    \node[] (F) at (0,0){$F$};
    }
    Il grafo $G$ ha connettività $K(G) \leq d(v)$. Siccome $d(v) = |F| = \delta(G)$ vale che $K(G) \leq |F|$.
\end{dimo}

\chapter{Terza lezione}

\section{Cammino euleriano}

\noindent
Un cammino \textbf{chiuso} (in inglese closed walk) è un ciclo in cui i vertici non sono distinti. Un cammino chiuso si dice \textbf{euleriano} se attraversa tutti gli archi del grafo esattaemente una volta. Un grafo è euleriano se ammette un cammino euleriano.

\begin{teo} \textbf{Teorema di Eulero (1746)}

\noindent 
Un grafo connesso è euleriano se e solo se ogni vertice ha grado pari.
\end{teo}

\begin{dimo}
    Cominciamo con dimostrare il lato $=>$ del teorema. Quindi, dato un grafo connesso euleriano questo ogni vertice ha grado pari. Prendiamo un vertice che si trova sul cammino euleriano.
    \disegna{
        \node[nodo] (X) {};
        \node[nodo] (A) at (1,1.5) {};
        \node[nodo] (B) at (1,-1.5) {};
        \node[nodo] (C) at (-1,1.5) {};
        \node[nodo] (D) at (-1,-1.5) {};
        \node[nodo] (E) at (-2,0.75) {};
        \draw[>= stealth]  (X) edge [out=60,in=-60,distance=7mm]   (A);
        \draw[>= stealth]  (X) edge [out=-30,in=110,distance=7mm]   (B);
        \draw[>= stealth]  (X) edge [out=110,in=-30,distance=7mm]   (C);
        \draw[>= stealth]  (X) edge [out=-100,in=60,distance=7mm]   (D);
        \draw[>= stealth, dotted]  (X) edge [out=120,in=60,distance=7mm]   (E);
    }
    \noindent
    Se il cammino passa per il vertice, allora deve sia entrare che uscire. Non può esserci un arco che collega un vicino che non sia nel cammino. Quindi o un vertice è isolato oppure il cammino esce ed entra. Allora devono avere grado pari.
    
    L'altro verso necessita un po' più di lavoro per essere dimostrato. Quello che vogliamo dimostrare è che se ogni vertice ha grado pari allora il grafo è euleriano.  Facciamo una dimostrazione per induzione su $|E|$.

    \noindent 
    \textbf{Caso base} $|E| = 0$, banale. Implica che $|V| = 1$ perché parliamo di grafi connessi.

    \noindent 
    \textbf{Ipotesi induttiva} $|E| \geq  1$. Enunciamo un fatto utile.

    \begin{fatto}
        Se $G$ ha tutti i vertici con grado pari con $E \leq 1$, posso trovare in $G$ un cammino chiuso che non contiene un arco \textbf{più} di una volta. 
    \end{fatto}

    \noindent
    Sia $\omega$ un tale cammino di lunghezza massima. Ne rappresentiamo uno da esempio in figura.
    
    \disegna{
        \node[nodo] (A) at (0,0) {};
        \node[nodo] (B) at (1,1) {};
        \node[nodo] (C) at (2,0) {};
        \node[nodo] (D) at (1,-1) {};
        \node[nodo] (E) at (-1,1) {};
        \node[nodo] (F) at (-1,-1) {};
        \node[nodo] (G) at (-2,0) {};

        \draw[] (A) -- (B);
        \draw[] (A) -- (E);
        \draw[] (A) -- (D);
        \draw[] (A) -- (F);
        \draw[] (B) -- (C);
        \draw[] (C) -- (D);
        \draw[] (G) -- (E);
        \draw[] (G) -- (F);
    }

    \noindent 
    Definiamo come $F$ l'insieme degli archi di $\omega$. Se $F \equiv E$ allora abbiamo finito, dato che tutti gli archi di $G$ fanno parte del cammino $\omega$. Assumiamo per assurdo che non sia così. Allora deve valere $$E' \equiv E \backslash F \neq \varnothing$$ 
    Notiamo che $\forall v \in V$ un numero pari di $u \in N(v)$ appartiene a $F$.  Allora il sotto-grafo $G' = (V,E')$ ha tutti i vertici di grado pari (ricordiamo che $0$ è pari). E' evidente che ci debba essere almeno n nodo $e$ attaccato al cammino, altrimenti il grafo non sarebbe connesso.

        
    \disegna{
        \node[nodo] (A) at (0,0) {};
        \node[nodo] (B) at (1,1) {};
        \node[nodo] (C) at (2,0) {};
        \node[nodo] (D) at (1,-1) {};
        \node[nodo] (E) at (-1,1) {};
        \node[nodo] (F) at (-1,-1) {};
        \node[nodo] (G) at (-2,0) {};
        \node[nodo] (H) at(2,2){};
        \node[] at (2,2.3){$e$}; 
        
        \draw[] (A) -- (B);
        \draw[] (A) -- (E);
        \draw[] (A) -- (D);
        \draw[] (A) -- (F);
        \draw[] (B) -- (C);
        \draw[] (C) -- (D);
        \draw[] (G) -- (E);
        \draw[] (G) -- (F);
        \draw[dashed] (B) -- (H);
    }
    Sia $C$ la componente di $G'$ che contiene $e$. $C$ ha un numero di archi $< |E|$, dato che almeno un arco l'abbiamo rimosso. Per ipotesi induttiva $C$ contiene un cammino euleriano. Ma allora possiamo costruire un cammino euleriano per $G$ unendo $\omega$ e il cammino trovato in $C$. Quindi abbiamo costruito un cammino più lungo di $\omega$, contraddicendo l'ipotesi che sia massimo. Allora $F \equiv E$ e così abbiamo dimostrato il teorema. 
\end{dimo}

\noindent 
Se un grafo è euleriano possiamo trovare un cammino euleriano in tempo $O(|E|)$, i.e. in tempo lineare nella descrizione del grafo (algoritmo di Hierholzer). 

\section{Ciclo hamiltoniano}
Un \textbf{ciclo hamiltoniano} è un ciclo che contiene tutti i vertici.  Un grafo si dice hamiltoniano se contiene un ciclo hamiltoniano. Non è nota alcuna condizione necessarie e sufficiente affinché un grafo sia hamiltoniano. Sono note solamente condizioni sufficienti.

\begin{teo}
    Teorema di Dirac (1952).

    \noindent
    Un grafo $G = (V,E)$ con $|V| \geq 3$ e $\delta(G) \geq \frac{|V|}{2}$ è hamiltoniano. 
\end{teo}

\begin{dimo}
    Cominciamo con dimostrare che $G$ deve essere connesso. Se per assurdo non lo fosse allora ha almeno due componenti. 

    \disegna{
     \node[cloud,draw,minimum width = 2.5cm,
    minimum height = 3cm] at(-2,0) {};
    \node[cloud,draw,minimum width = 2.8cm,
    minimum height = 3cm] at(2,0) {};
 }
    Ogni componente è tale che $|C| \leq \frac{|V|}{2}$. Questo è ovvio, perché se una componente ne avesse più di $\frac{|V|}{2}$, un'altra dovrebbe averne di meno, e quindi non varrebbe la condizione $\delta(G) \geq \frac{|V|}{2}$. Notiamo ora che $$\forall v \in C \; d(v) \leq |C| - 1 $$ poiché al massimo un nodo può avere un arco con tutti gli altri nodi nella componente. Questa affermazione ci porta a poter dire che 
    $$d(v) \leq |C| - 1 < \frac{|V|}{2}$$
    ovvero
    $$d(v) < \frac{|V|}{2}$$
    che viola le ipotesi. 
    Sappiamo che $G$ è connesso. Sia ora $p$ un cammino di lunghezza massima in $G$ con nodi $v_0,v_1,\dots,v_k$, con archi $(v_i,v_{i+1})$, dove $v_i$ viene detto \textbf{vertice sinistro} e $v_{i+1}$ \textbf{vertice destro}.

    \disegna{
        \node[nodo] (A) at (-2,0){};
        \node[] at (-2,0.3){$v_0$};
        \node[nodo] (B) at (-1,0){};
        \node[] at (-1,0.3) {$v_1$};
        \node[nodo] (C) at (0,0){};
        \node[] at (0,0.3) {$v_i$};
        \node[nodo] (D) at (1,0){};
        \node[] at (1,0.3) {$v_{1+1}$};
        \node[nodo] (E) at (2,0){};
        \node[] at (2,0.3) {$v_{k-1}$};
        \node[nodo] (F) at (3,0){};
        \node[] at (3,0.3) {$v_{k}$};

        \draw[] (A) -- (B);
        \draw[dashed] (B) -- (C);
        \draw[] (C) -- (D);
        \draw[dashed] (D) -- (E);
        \draw[] (E) -- (F);
    }

    \noindent 
    Tutti i vicini di $v_0$ e $v_k$ sono nel cammino, altrimenti posso allungarlo aggiungendoli. Ricordiamo che vale anche $d(v_i) \geq \frac{n}{2}$ dove $n = |V|$. $p$ non può avere più di $n$ archi, quindi la sua lunghezza $k$ è tale che
        $$k \leq n-1$$
    dove non può essere $k \geq n$ sennò ripeterei dei nodi (e quindi non sarebbe un cammino). Ora associamo a ogni vicino di $v_0$ l'arco a sinistra (per esempio a $v_i$ associamo $(v_{i-1},v_i)$) e a ogni vicino di $v_k$ l'arco a destra. Per il principio della piccionaia c'è almeno un arco che è preso sia da un vicino di $v_0$ che da un vicino i $v_k$

    \disegna{
        \node[nodo] (A) at (-2,0){};
        \node[] at (-2,0.3){$v_0$};
        \node[nodo] (B) at (-1,0){};
        \node[] at (-1,0.3) {$v_1$};
        \node[nodo] (C) at (0,0){};
        \node[] at (0,0.3) {$v_i$};
        \node[nodo] (D) at (1,0){};
        \node[] at (1,0.3) {$v_{1+1}$};
        \node[nodo] (E) at (2,0){};
        \node[] at (2,0.3) {$v_{k-1}$};
        \node[nodo] (F) at (3,0){};
        \node[] at (3,0.3) {$v_{k}$};

        \draw[color= blue] (A) -- (B);
        \draw[dashed] (B) -- (C);
        \draw[color = orange] (C) -- (D);
        \draw[dashed] (D) -- (E);
        \draw[color = red] (E) -- (F);
        \draw[>= stealth, dashed]  (A) edge [out=-60,in=-120,distance=7mm]   (D);
        \draw[>= stealth, dashed]  (F) edge [out=120,in=60,distance=8mm]   (C);
    }

    \noindent 
    Possiamo costruire un ciclo che va da $v_0$ a $v_i$, poi da $v_i$ raggiunge $v_k$, da $v_k$ a $v_{i+1}$ e poi $v_0$.

    \disegna{
        \node[nodo] (A) at (-2,0){};
        \node[] at (-2,0.3){$v_0$};
        \node[nodo] (B) at (-1,0){};
        \node[] at (-1,0.3) {$v_1$};
        \node[nodo] (C) at (0,0){};
        \node[] at (0,0.3) {$v_i$};
        \node[nodo] (D) at (1,0){};
        \node[] at (1,0.3) {$v_{1+1}$};
        \node[nodo] (E) at (2,0){};
        \node[] at (2,0.3) {$v_{k-1}$};
        \node[nodo] (F) at (3,0){};
        \node[] at (3,0.3) {$v_{k}$};

        \draw[color= blue] (A) -- (B);
        \draw[dashed, color = blue] (B) -- (C);
        \draw[] (C) -- (D);
        \draw[dashed, color = red] (D) -- (E);
        \draw[color = red] (E) -- (F);
        \draw[>= stealth, color = red]  (A) edge [out=-60,in=-120,distance=7mm]   (D);
        \draw[>= stealth, color = blue]  (F) edge [out=120,in=60,distance=8mm]   (C);
    }

    \noindent 
    Se esistesse un vertice che non facesse parte di questo ciclo, sarebbe sicuramente un vicino, dato che il grafo è connesso. Ma allora potrei usarlo per allungare il percorso $p$ violando l'ipotesi di massimalità. Quindi il ciclo passa per tutti i nodi, i.e. è hamiltoniano.
    
\end{dimo}

\noindent
Il problema di determinare se un grafo $G$ contenga un cammino hamiltoniano è  NP-completo, questo spiega  il motivo per cui non c siano delle condizioni necessarie e sufficienti. 

\section{Grafo bipartito}
Un grafo $G = (V,E)$ è detto \textbf{bipartito} se $\exists $ una partizione $V_1,V_2$ di $V$ tali che $\forall (i,j) \in E \; i \in V_1 \land j \in V_2$ o viceversa.
Ricordiamo che $V_1$ e $V_2$ in quanto partizione di $V$ sono tali che $V_1 \cap V_2 \equiv  $ $V_1 \cup V_2 = \varnothing$.

\begin{exmp}
    I grafi bipartiti sono usati per esempio su Tinder, Amazon e Netflix.

    \disegna{
    \node[nodo] (A) at(-1.6,0.9){};
    \node[nodo] (A1) at(-1.6,0.3){};
    \node[nodo] (A2) at(-1.6,-0.3){};
    \node[nodo] (A3) at(-1.6,-0.9){};
    \node[nodo] (B2) at(1.6,0.9){};
    \node[nodo] (B) at(1.6,0.3){};
    \node[nodo] (B1) at(1.6,-0.3){};
    \node[nodo] (B3) at(1.60,-0.9){};
    \draw[] (A)--(B1);
    \draw[] (A1)--(B);
    \draw[] (A2) -- (B3);
    \draw[] (A3) -- (B3);
    \draw[] (A3) -- (B2);
    \draw (-1.5,0) ellipse (0.5cm and 2cm);
    \draw (1.5,0) ellipse (0.5cm and 2cm);
    \node[] (V1) at (-0.5,-2){$V_1$};
    \draw[->,>= stealth]  (V1) edge [out=-140,in=-60,distance=7mm]   (-1,-1.85);
    \node[] (V2) at (0.5,-2){$V_2$};
    \draw[->,>= stealth]  (V2) edge [out=-60,in=-140,distance=7mm]   (1,-1.85);
    }

    \noindent 
    Possono contenere cicli, che sono sempre pari! Vale anche il viceversa, ovvero un grafo che contiene solo cicli di lunghezza pari è bipartito.
\end{exmp}


\chapter{Quarta lezione}
\section{Parametri dei grafi}

Possiamo definire informalmente un \textbf{parametro} come una proprietà. Ne abbiamo già viste alcune: 

\begin{itemize}
    \item Taglia
    \item Numero di lati
    \item Diametro
    \item Calibro
\end{itemize}
Formalmente un parametro è una funzione 

$$\phi: \mathscr{G} \rightarrow \mathbf{R}$$
dove $\mathscr{G}$ è la classe dei grafi non orientati e semplici. Altre possibili proprietà possono essere:

\begin{itemize}
    \item $G$ è euclideo?
    \item $K_3 \subseteq G$?
\end{itemize}
I parametri sono detti \textbf{invarianti}, ovvero mantengono lo stesso valore tra \textbf{isomorfismi} di grafi. 
\begin{defi}
    Dati due grafi $G,H \in \mathscr{G}$ sono isomorfismi se $\exists f: V(G) \rightarrow V(H)$ con $f$ biettiva tale che  $$\{(x,y)\} \in E(G) \Longleftrightarrow \{f(x),f(y)\} \in E(H)$$
    $f$ è detto isomorfismo tra $G$ e $H$.
\end{defi}

\noindent
Tutti i $\phi$ sono isomorfismi.

\subsection{Numero di indipendenza}

\begin{defi}
    $U \subseteq V$ è indipendente in $G = (V,E)$ se $$\forall x,y \in U \{x,y\} \notin E$$
    In altre parole $G[U] = (V,\varnothing)$ è un grafo privo di lati.
\end{defi}

\begin{defi}
    $\alpha(G)$ è detto \textbf{numero di indipendenza} ed è tale che
    \begin{multline*}
    \alpha(G) := \max\{k \in \mathbb{N} | \exists U \subseteq V \; \\ \text{indipendente in }\;  G  \land |U|= k \}
    \end{multline*}

\end{defi}

\noindent
Il problema di trovare il numero di indipendenza maggiore è NP-completo.  Notiamo che $\alpha(G)$ sommato alla dimensione più piccola di vertex cover in $G$ è uguale a $|V|$.

\disegna{

\node[cloud,draw,minimum width = 2.5cm,
    minimum height = 3cm] at (-2,0) {};

\node[cloud,draw,minimum width = 2.5cm,
    minimum height = 3cm] at (2,0) {};
\node[] at (-2,2) {$U$};
\node[] at (2,2) {$V \backslash U$};
\node[nodo] (A) at (1.8,-0.4) {};
\node[nodo] (B) at (2.2,0.2) {};
\node[nodo] (C) at (1.5,0.5) {};
\draw (A) -- (B);
\draw (B) -- (C);
\node[nodo] (D) at (-1.8,0.1){};
\node[nodo] (E) at (-2.4,0.8){};
\draw (A) -- (D);
\draw (C) -- (D);
\draw (E) -- (B);
}

\noindent 
Notiamo infatti che i nodi in $U$ hanno almeno un arco con un nodo in $V\backslash U$, altrimenti il grafo sarebbe sconnesso. Notiamo anche che, per definizione, i nodi in $U$ non sono collegati tra loro. Inoltre, ogni nodo in $V\backslash U$ è collegato ad almeno un nodo in $U$, altrimenti $U$ non sarebbe massimale. E' quindi evidente che per coprire tutti gli archi ho bisogno  di tutti i nodi di $V\backslash U$. Assumiamo per assurdo che non sia così, e ci sia un nodo $\omega$ di $V \backslash U$ che non usiamo. Allora gli archi tra $\omega$ e $U$ non sono coperti. Per metterci in un caso favorevole assumiamo anche che gli archi $(j,\omega) \in E$ tali che $j \in V \backslash U $ siano già coperti da $j$ (se così non fosse avremmo bisogno di $\omega$ per coprirli e quindi avremmo dimostrato la sua necessità). I nodi in $i \in U$ tali che $(i,\omega) \in E$ devono essere parte della vertex cover, altrimenti non copriamo degli archi. Tuttavia, se invece di scegliere $\omega$ scegliamo $i$, la cardinalità resterebbe la stessa. Ma se $i$ coprisse due archi, $(i,\omega)$ e $(i,\omega_1)$ tale che $\omega_1 \in V \backslash U$, allora potremmo scegliere $i$ per coprirli entrambi, ottenendo una cardinalità minore. Ma se $\omega,\omega_1$ hanno altri archi con nodi in $U$, allora questi sarebbero scoperti, e andrebbero coperti aggiungendo dei nodi, vanificando il vantaggio ottenuto. Se però non ne hanno altri allora $\omega,\omega_1$ formano, insieme a $U \backslash i$ un insieme indipendente più grande, e ciò non è possibile.

\subsection{Numero di clique}

\begin{defi}
    Il \textbf{numero di clique} è definito come 
    \begin{multline*}
        \omega(G) := \max\{k \in \mathbb{N} | \exists U \subseteq V,\\ G[U] \; \text{completo con} \; |U| = k\}
    \end{multline*}
\end{defi}

\noindent 
Il problema di trovare il numero di cricca massimo è NP-completo. Una cricca in $G =(V,E)$ è un insieme indipendente in $\bar G$ ($G$ \textbf{complemento}), dove $\bar G$ è definito come 

$$\bar G = (V , [V]^2 \backslash E)$$

\begin{exmp} In figura $G$ e il suo complemento.
    \disegna{
        \node[nodo] (A) at (-3,1) {};
        \node[nodo] (B) at (-3,-1) {};
        \node[nodo] (C) at (-1,1) {};
        \node[nodo] (D) at (-1,-1) {};
        \draw[] (C) -- (B);
        \draw[] (A) -- (C);
        \draw[] (B) -- (D);
        \draw[] (D) -- (C);
        \node[nodo] (A1) at (1,1) {};
        \node[nodo] (B1) at (1,-1) {};
        \node[nodo] (C1) at (3,1) {};
        \node[nodo] (D1) at (3,-1) {};
        \draw[] (A1) -- (B1);
        \draw[] (A1) -- (D1);
    }
\end{exmp}

\subsection{Numero cromatico}

\begin{defi}
    Una \textbf{coloratura} dei vertici $G=(V,E)$ è una funzione
    $$c\;:\; V \rightarrow \{1,\dots,k\}$$
    tale che $\{x,y\} \in E \Rightarrow c(x) \neq c(y)$.
\end{defi}
 La funzione $c$ associa a ogni nodo un colore (indicato con un numero). Una coloratura con $k$ colori è detta \textbf{k-coloratura}. Un grafo si dice \textbf{k-colorabile} se $\exists $ k-coloratura $c$. Il \textbf{numero cromatico} è definito come $$\chi(G) = \min{\{k \in \mathbb{N} | G \; \text{è k-colorabile}\}}$$
Anche il problema di trovare $\chi(G)$ è NP-completo.

\begin{exmp}
    Il caso in $k = 2$ è possibile se e solo se il grafo è bipartito.

    
    \disegna{
    \node[nodo,color = red] (A) at(-1.6,0.9){};
    \node[nodo,color = red] (A1) at(-1.6,0.3){};
    \node[nodo,color = red] (A2) at(-1.6,-0.3){};
    \node[nodo,color = red] (A3) at(-1.6,-0.9){};
    \node[nodo,color = blue] (B2) at(1.6,0.9){};
    \node[nodo,color = blue] (B) at(1.6,0.3){};
    \node[nodo,color = blue] (B1) at(1.6,-0.3){};
    \node[nodo, color = blue] (B3) at(1.60,-0.9){};
    \draw[] (A)--(B1);
    \draw[] (A1)--(B);
    \draw[] (A2) -- (B3);
    \draw[] (A3) -- (B3);
    \draw[] (A3) -- (B2);
    \draw (-1.5,0) ellipse (0.5cm and 2cm);
    \draw (1.5,0) ellipse (0.5cm and 2cm);
    }
\end{exmp}

\begin{exmp}
    Quanti colori ci servono per una cricca di $n$ elementi?

    \disegna{
        \node[nodo, color = blue] (A) at (0,1){};
        \node[nodo, color = orange] (B) at (-1,-1){};
        \node[nodo, color = red] (C) at (1,-1){};
        \node[] (T1) at (3,0){$K_3$}; 
        \draw[] (A) -- (B);
        \draw[] (B) -- (C);
        \draw[] (A) -- (C);

        \node[nodo, color = blue] (D) at (-1,-3){};
        \node[nodo, color = purple] (E) at (1,-3){};
        \node[nodo, color = green] (F) at (-1,-5){};
        \node[nodo, color = orange] (G) at (1,-5){};
        \node[] (T1) at (3,-4){$K_4$}; 
        \draw[] (D) -- (E);
        \draw[] (E) -- (F);
        \draw[] (F) -- (G);
        \draw[] (G) -- (D);
        \draw[] (G) -- (E);
        \draw[] (D) -- (F);
    }

    \noindent 
    In generale per una cricca di $n$ elementi ci servono $n$ colori.
\end{exmp}

\begin{exmp}
    Quanti colori ci servono per un ciclo?
    Se il ciclo è pari, $C_{2n}$
        \disegna{
        \node[nodo, color = blue] (A) at (-4,0){};
        \node[nodo, color = red] (B) at (-2,1){};
        \node[nodo, color = blue] (C) at (0,1.5){};
        \node[nodo, color = red] (D) at (2,1){};
        \node[nodo, color = blue] (E) at (1,-0.3){};
        \node[nodo, color = red] (F) at (-2,0){};
        \node[nodo, color = blue] (G) at (0,-1){};
        \node[nodo, color = red] (H) at (-3,-0.5){};
        \draw[] (A) -- (B);
        \draw[] (B) -- (C);
        \draw[] (C) -- (D);
        \draw[] (D) -- (E);
        \draw[] (E) -- (F);
        \draw[] (F) -- (G);
        \draw[] (G) -- (H);
        \draw[] (H) -- (A);
    }
    \noindent 
    Ci servono $2$ colori, se invece il ciclo è dispari, $C_{2n + 1}$
      \disegna{
        \node[nodo, color = blue] (A) at (-4,0){};
        \node[nodo, color = red] (B) at (-2,1){};
        \node[nodo, color = blue] (C) at (0,1.5){};
        \node[nodo, color = red] (D) at (2,1){};
        \node[nodo, color = blue] (E) at (1,-0.3){};
        \node[nodo, color = red] (F) at (-2,0){};
        \node[nodo, color = blue] (G) at (0,-1){};
        \node[nodo, color = red] (H) at (-2,-3){};
        \node[nodo, color = orange] (I) at (-3,-1){};
        \draw[] (A) -- (B);
        \draw[] (B) -- (C);
        \draw[] (C) -- (D);
        \draw[] (D) -- (E);
        \draw[] (E) -- (F);
        \draw[] (F) -- (G);
        \draw[] (G) -- (H);
        \draw[] (H) -- (I);
        \draw[] (I) -- (A);
    }
    \noindent 
    Ci servono $3$ colori.
\end{exmp}

\begin{teo}
    Teorema dei quattro colori.
    $$\chi(G) \leq 4 \; \forall G \; \text{planare}$$
    dove con \textbf{planare} intendiamo uno grafo tale per cui esiste una rappresentazione grafica in cui gli archi non si intersecano.
\end{teo}

\begin{fatto} Diamo un upper-bound per $\chi(G)$

$$\chi(G) \leq \frac{1}{2}  + \sqrt{2 |E| + \frac{1}{4}}$$

\end{fatto}

\begin{dimo}
    Poniamo $x = \chi(G)$.
    Se $G$ è $k$-colorabile allora $\exists$ partizione $V_1,\dots,V_k$ tale che $V_i$ è indipendente e $\forall i \; V_i= \{v \in V | c(v) = i\} = C^{-1}(i)$, dove $C^{-1}(i)$ è la preimmagine. $c$ è la funzione che assegna a ogni partizione un colore,

    $$c\;:\; V \rightarrow \{1,\dots,k\}$$
    Non è possibile che esistano due partizioni non collegate tra loro, altrimenti avremmo un numero di insiemi indipendenti minore e $k$ non sarebbe massimo.

    \disegna{
        \node[cloud,draw,minimum width = 2.5cm,
    minimum height = 3cm] (A) at (-2,0) {};
        \node[] at (-2,0){$V_1$};
        \node[cloud,draw,minimum width = 2.5cm,
    minimum height = 3cm] (B) at (2,0) {};
         \node[] at (2,0){$V_2$};
        \node[cloud,draw,minimum width = 2.5cm,
    minimum height = 3cm] (C) at (-2,-4) {};
        \node[] at (-2,-4){$V_4$};
        \node[cloud,draw,minimum width = 2.5cm,
    minimum height = 3cm] (D) at (2,-4) {};
        \node[] at (2,-4){$V_3$};
        \draw[] (A)--(B);
        \draw[] (A)--(C);
        \draw[] (A)--(D);
        \draw[] (B)--(C);
        \draw[] (B)--(D);
        \draw[] (C)--(D);
    }

    \noindent 
    Ovvero $\forall i \neq j \; \exists \geq 1$ lato tra $V_i,V_j$. E' ovvio che il numero di lati nel grafo è maggiore uguale del numero di coppie di partizioni presenti
    $$|E| \geq \text{\#coppie}(V_i,V_j)$$
    dove il numero di coppie è $$\binom{k}{2} = \frac{k(k-1)}{2}$$
    Quindi....

    $$|E| \geq \frac{k(k-1)}{2}$$
    $$2|E| \geq k(k-1)$$
    $$k^2 -k -2|E| \geq 0$$
    prendiamo l'equazione associata $k^2 -k -2|E| = 0$ e la risolviamo

    $$k_{1,2} = \frac{1 \pm \sqrt{1 + 8|E|}}{2}$$
    $$= \frac{1}{2} \pm \frac{\sqrt{1 + 8|E|}}{2} = \frac{1}{2} \pm \frac{\sqrt{4(\frac{1}{4} + 2|E|)}}{2} $$
    $$\frac{1}{2} \pm \frac{2\sqrt{(\frac{1}{4} + 2|E|)}}{2} =  \frac{1}{2} \pm \sqrt{(\frac{1}{4} + 2|E|)}$$
    Quindi 

    \begin{multline*}
            \frac{1}{2} - \sqrt{(\frac{1}{4} + 2|E|)} \leq \chi(G) \\ \leq \frac{1}{2} + \sqrt{(\frac{1}{4} + 2|E|)}
    \end{multline*}
    Abbiamo dimostrato il teorema.
\end{dimo}

\noindent 
Notiamo grafi con gradi alti richiedono più colori rispetto a grafi con gradi più bassi. 

\begin{fatto} Vale quanto segue 

$$\forall G \; \chi(G) \leq \Delta(G) + 1$$
Se $G$ è una cricca o un ciclo di lunghezza dispari allora è un'uguaglianza.
\end{fatto}

\begin{dimo}
    Supponiamo \\ $v_1,\dots,v_n$ arbitrario. Allora procediamo in questo modo:

    \begin{enumerate}
        \item Assegniamo $1$ a $v_1$
        \item Se $v_2$ è vicino di $v_1$ assegniamo $2$, altrimenti $1$.
    \end{enumerate}
    e così via, fino ad assegnare tutti gli $n$ nodi. Siccome sappiamo che vale $\forall i \delta(v_i) \leq \Delta(G)$ per definizione, allora se arriviamo all'$i$-esimo nodo, avendo assegnato già $\Delta(G) + 1$ colori diversi, allora non ne abbiamo bisogno di uno nuovo per $v_i$ dato che al massimo $\Delta(G)$ vicini e ci sono $\Delta(G) + 1$ colori disponibili.
\end{dimo}

\begin{fatto}
    Vale che 

    $\forall G  \; \chi(G) \cdot \alpha(G) \geq |V|$
\end{fatto}

\begin{dimo}
    Poniamo \\ $k = \chi(G)$. Sia $V_1,\dots,V_k$ una partizione indotta da una $k$-colorazione di $G$. Allora

    $$\sum_{i = 1}^k |V_i|  = |V|$$
    Sapendo che $|V_i| \leq \alpha(G)$ possiamo scrivere

    $$|V| \leq \sum_i \alpha(G)  = k \alpha(G) = \chi(G) \alpha(G)$$ Abbiamo dimostrato il fatto.
\end{dimo}


\chapter{Quinta lezione}

\noindent
Terminiamo la lezione precedente enu\\nciando un fatto:

\begin{fatto}
    Vale quanto segue 

    $$\chi(G) \geq \omega(G)$$
\end{fatto}
Proseguiamo presentando il teorema di \textbf{Turán}.

\begin{teo}
    Teorema di Turán. $\forall G = (V,E)$ vale che  $$\alpha(G) (d(G) + 1) \geq |V|$$
\end{teo}

\noindent 
Dividendo per $d(G) + 1 $ ambo i membri otteniamo un minorante per $\alpha(G)$. Prima di dimostrare il teorema introduciamo la \textbf{disuguaglianza di Jensen}. Data una variabile aleatoria $X \in \mathbb{R}$ tale che $X \sim P$ (dove $P$ possiamo pensarla come una distribuzione empirica. Diamo probabilità uniforme agli elementi. Il valore atteso diventa la media). Sia $f : \mathbb{R} \rightarrow \mathbb{R}$ una funzione convessa. Allora vale che 
$$f(\va[X]) \leq \va[f(x)]$$
Intuitivamente possiamo pensare 

\vspace{5px}

\trimbox{1cm 0cm 0cm 0cm}{
\begin{tikzpicture}[domain=0:2]
           \begin{axis} [xlabel = x, ylabel = y, axis lines=center, ymin = -1,  yticklabel=\empty, xticklabel = \empty, clip = false]            \addplot[color=white,samples=100,smooth,ultra thick] {(2*x-1)^2 + 1 };
           \addplot[color = white] coordinates {(0.5,0)} node[below] (A) {$x$};
           \addplot[color = white] coordinates {(1.5,0)} node[below] (B) {$y$};
           \addplot[color = white,dashed] coordinates{(0.5,0) (0.5,1)};
           \addplot[color = white,dashed] coordinates{(1.5,0) (1.5,5)};
           \addplot[color = white] coordinates {(1,0)} node[below] (C) {$\frac{x+y}{2}$};
           \addplot[color = white,dashed] coordinates{(1,0) (1,2)};
           \addplot[color = white] coordinates {(0,1)} node[left] {$f(x)$};
            \addplot[color = white,dashed] coordinates{(0,1) (0.5,1)};
            \addplot[color = white] coordinates {(0,2)} node[above left] {$f(\frac{x+y}{2})$};
            \addplot[color = white,dashed] coordinates{(0,2) (1,2)};
             \addplot[color = white] coordinates {(0,5)} node[ left] {$f(y)$};
            \addplot[color = white,dashed] coordinates{(0,5) (1.5,5)};

            \addplot[color = red] coordinates {(0,3)} node[above right] {$\frac{f(x) + f(y)}{2}$};
            \addplot[color = red] coordinates{(0.5,1) (1.5,5)};
            \addplot[color = red] coordinates{(0,3) (1,3)};
            \end{axis}
\end{tikzpicture}
}

\vspace{5px}
\noindent 
Notiamo che, visivamente, la disuguaglianza di Jensen ha senso, dato che $$\frac{f(x) + f(y)}{2} \geq f(\frac{x+2}{2})$$

\begin{dimo}
    Possiamo ora dimostrare il teorema di Turán. Facciamo una dimostrazione costruttiva, ovvero dimostriamo l'esistenza di un oggetto matematico creando un metodo per costruire tale oggetto. Nel nostro caso costruiremo una serie di grafi, $G = G_1 = G_2 = \dots = G_i$ dove ogni grafo è tale che $G_i = (V_i,E_i)$.

\begin{algorithm}
\caption{}\label{euclid}
\begin{algorithmic}[1]
\State $i \gets 1$
\While {$G_i \neq 0$}
\State $\text{Sia} \; v_i \in argmin_{\;v \in V_i} d_i(v) \;$ $\text{ovvero un vertice di grado}$ $\text{minimo}$
\State $G_{i+1} \gets G_i - C_i(v_i)$
\State $i \gets i + 1$
\EndWhile
\State \Return $\{v_1,\dots,v_i\}$
\end{algorithmic}
\end{algorithm}

\noindent 
$C_i(v) = N_i(v) \cup \{v\}$ è definito come il \textbf{vicinato esteso} di $v$ in $G_i$. Quello che fa l'algoritmo sopra descritto è prendere, a ogni iterazione, uno dei nodi con grado minimo e rimuoverlo, insieme a tutti i nodi vicini.
I nodi $v_i$ che scegliamo formano un insieme indipendente. Infatti non può esistere una situazione del tipo

\vspace{5px}

\begin{tikzpicture}
    \node[squarednode,minimum width=5cm](A3)[]{};
    \node[nodo, color = red] (v) at (-1,0){};
    \node[] at (-1,0.25){$v_i$};
    \node[nodo, color = red] (vj) at (1,0.50){};
    \node[] at (1,0.80){$v_j$};
    \node[nodo] (A) at (-1.75,0.5){};
    \node[nodo] (B) at (-1.5,-0.5){};
    \node[nodo] (C) at (-0.4,-0.90){};
    \node[nodo] (D) at (2,0.50){};
    \draw[] (v) -- (A);
    \draw[] (v) -- (B);
    \draw[] (v) -- (C);
    \draw[] (vj) -- (C);
    \draw[] (vj) -- (D);
    \draw[dashed] (v) -- (vj);

    \node[] (X1) at (-0.35,0.45){};
    \node[] (X2) at (0.5,0.05){};
    \node[] (Y1) at (0.35,0.65){};
    \node[] (Y2) at (-0.25,-0.15){};

    \draw[color = red, very thick] (X1) -- (X2);
    \draw[color = red, very thick] (Y1) -- (Y2);
\end{tikzpicture}

\noindent 
Se tra $v_i$ e $v_j$ esistesse un arco, allora scegliendo $v_i$ avremmo eliminato $v_j$ (o viceversa), e quindi non avremmo potuto sceglierlo successivamente. 

Sia $m$ l'iterazione dell'algoritmo. Sappiamo che $m \leq |V|$ e che $m \leq \alpha(G)$, dato che $\{v_1,\dots,v_m\}$ formano un insieme indipendente. Definiamo 

$$Q(G) = \sum_{v \in V_g} \frac{1}{1 + D_G(V)}$$
A ogni passo $G_i$ decresce, quindi

$$Q(G_1) - Q(G_2) \geq 0$$
Cerchiamo un upper-bound per questa sottrazione.
Per definizione scriviamo

$$G(G_1) - Q(G_2) = \sum_{u \in G_1(v_1)} \frac{1}{1 + d(u)}$$
Sappiamo che a ogni iterazione il numero di vicini di un grafo può solo diminuire, quindi 

$$\sum_{u \in G_1(v_1)} \frac{1}{1 + d(u)} \leq \sum_{u \in G_1(v_1)} \frac{1}{1 + d_1(u)}$$
dove abbiamo utilizzato $d_1$ al posto di $d$. Sappiamo inoltre che, per ogni scelta di $v_i$, vale $d_i(u) \geq d_i(v_i) \; \forall u \in V $ per la definizione stessa di $v_i$. 

$$\sum_{u \in G_1(v_1)} \frac{1}{1 + d_1(u)} \leq \sum_{u \in G_1(v_1)} \frac{1}{1 + d_1(v_1)}  $$

$$= \frac{|C_1(v_1)|}{1 + d_1(v_1)} = \frac{1 + d_1(v_1)}{1 + d_1(v_1)}  = 1$$
Riprendiamo la definizione di $Q(G)$

$$Q(G) = \sum_{v \in V_g} \frac{1}{1 + d_G(V)}$$
e riscriviamola come

$$= \sum_{i = 1}^m \sum_{u \in C(v_i)} \frac{1}{1 + d(u)}$$

$$\leq \sum_{i = 1}^m 1 = m \leq \alpha(G)$$
Se dividiamo l'equazione originale per $|V|$ otteniamo

$$\frac{Q(G)}{|V|} = \frac{\sum_{v \in V_g} \frac{1}{1 + d(V)}}{|V|}$$
Se poniamo $f(x) = \frac{1}{1+x}$

$$\frac{Q(G)}{|V|} = \frac{\sum_{v \in V_g} f(d(v))}{|V|}$$
Siccome $\frac{1}{1+x}$ è convessa per $x > -1$ possiamo applicare la disuguaglianza di Jensen. Poniamo $X \sim Unif(V)$ e $Y = d(X)$, quindi

$$\va[Y] = \sum_{v \in V} d(v) \cdot \frac{1}{|V|} = \frac{1}{|V|} \sum_{v \in V} d(v)$$
e
$$\va[f(Y)] = \sum_{v \in V} \frac{1}{|V|} \cdot f(d(v))$$
$$= \frac{1}{|V|} \sum_{v \in V} \frac{1}{1 + d(v)} \geq f(\va[Y])$$

$$= \frac{1}{1 + \frac{1}{|V|} \sum_{v \in V} d(v)} = \frac{1}{1 + d(G)}$$
Mettendo tutto assieme

$$\alpha(G) \geq Q(G) \geq \frac{|V|}{1 + d(G)}$$
quindi

$$\alpha(G) (d(G) + 1) \geq |V|$$
Inoltre possiamo dire che $d(G)$ è approssimabile in tempo polinomiale con fattore $O(\log{n})$
\end{dimo}

\noindent 
Presentiamo il seguente fatto:

\begin{fatto}
    La seguente disuguaglianza vale $\forall G = (V,E)$

    $$ \omega(G) (|V| - d(G)) \geq |V|$$
\end{fatto}

\begin{dimo}
    Poniamo $n = |V|$ e $\bar G = (V,\bar E)$. Sappiamo che 

    $$d_{\bar G} (v) = n - 1 - d_G(v)$$
    Quindi
    $$d(\bar G) = \frac{1}{n} \sum_{v \in V} d_{\bar G}(v) = \frac{1}{n} \sum_{v \in V} (n - 1 - d(G))$$
    Siccome un insieme indipendente  in $\bar G$ corrisponde a una clique in $G$, possiamo applicare il teorema di Turan 
    $$\omega(G) = \alpha(\bar G) \geq \frac{n}{1 + d(\bar G)} = \frac{n}{n - d(G)} $$
    E a questo punto abbiamo concluso la dimostrazione, infatti muovendo il denominatore
    $$\omega(G) (|V| - d(G)) \geq |V|$$
\end{dimo}

\section{Numero di dominazione}

\begin{defi}
    Il \textbf{numero di dominazione} è 

    \begin{multline*}
    \gamma(G):= \min\{k \in \mathbb{N} | \exists U \subseteq V\\ \; \text{dominante}, |V| = k\} 
    \end{multline*}
\end{defi}
\noindent 
Dove un \textbf{insieme di dominazione} è $U \subseteq V$ tale che ogni vertice in $V \backslash U$ ha un unico vicino in $U$. Un vertice domina se stesso.

Il problema di trovare $\gamma(G)$ è NP-completo.

Notiamo, inoltre, che se un insieme indipendente è dominante allora non domina alcun vertice dell'insieme indipendente.

\chapter{Sesta lezione}

\section{Proprietà numero di dominazione}

Continuiamo la trattazione del numero di dominazione, iniziata nella scorsa lezione.

\begin{fatto}
    $\forall  \; G = (V,E)$ vale che 
    $$\gamma(G) \leq \alpha(G)$$
\end{fatto}

\begin{dimo}
    Sia $U \subseteq V$ indipendente e $|U| = \alpha(G)$. Per assurdo, supponiamo che $U$ non sia dominante.  Allora $\exists \;x \in V\backslash U$ tale che non ha vicini in $U$. Questo implica che $x$ non è dominato da $U$. Allora $U \cup \{x\}$ è indipendente e ha cardinalità $\alpha(G) + 1$, ma questo è assurdo, perché $U$ non sarebbe l'insieme indipendente massimo. Allora $U$ deve essere dominante. Per definizione stessa di $\gamma(G)$ vale che 
    
    $$|U| = \alpha(G) \leq \gamma(G)$$
    Infatti, l'insieme dominante minimo al massimo ha come cardinalità $U$, dato che questo è dominante, e il minimo può essere solo uguale o più piccolo.
\end{dimo}

\noindent 
Il prossimo teorema mostra che se tutti i vertici di un grafo hanno un grado alto, allora il numero di dominazione deve essere piccolo.

\begin{teo}
    (Armautov, 1974; Payan, 1975; Lovász 1966)
    Vale la seguente disequazione

    $$\gamma(G) \frac{1 + \delta(G)}{1 + \ln{(1 + \delta(G))}} \leq |V|$$
\end{teo}

\begin{dimo}
    Facciamo una dimostrazione per costruzione. Cominciamo con il porre $n = |V|$ e $\delta = \delta(G)$.

\begin{algorithm}[H]
\caption{}\label{euclid}
\begin{algorithmic}[1]
\State $S \gets \varnothing$
\State $U \gets V$
\While {$U \neq \varnothing$}
\State $v' \in argmax_{v \in V} |U \cap C(v) \|$ 
\State $S \gets S \cup \{v'\}$
\State $U \gets U \backslash C(v')$
\EndWhile
\State \Return $S$
\end{algorithmic}
\end{algorithm}

\noindent 
Consideriamo un'iterazione qualsiasi dell'algoritmo. Sia $U$ l'insieme dei vertici non ancora dominati all'inizio di tale iterazione e poniamo $r = |U|$. Allora 

$$|U \cap C(v')|  = \sum_{u \in U} \mathds{I}\{u \in C(v')\}$$Esplicitiamo $v'$ come il nodo che massimizza la sommatoria
$$\max_{v \in V} \sum_{u \in U} \mathds{I}\{u \in C(v)\}$$ Definiamo la variabile aleatoria $X \sim Unif(V)$, dove la distribuzione è uniforme su $V$. Sappiamo che il massimo è sempre maggiore o uguale della media. Allora possiamo scrivere

$$\geq \va[\sum_{v \in U} \mathds{I}\{u \in C(X)\}]$$Per la linearità del valore atteso scriviamo
$$= \sum_{v \in U}  \va[\mathds{I}\{u \in C(X)\}]$$
Il valore atteso di una funzione indicatrice è la probabilità che avenga l'evento. 

$$= \sum_{v \in U} P(u \in C(X))$$
Notiamo ora che se $u$ fa parte del vicinato esteso di $X$, allora vale anche l'opposto, ovvero $X$ fa parte del vicinato esteso di $u$.

$$= \sum_{v \in U} P(X \in C(u))$$
La probabilità che $X$ faccia parte del vicinato esteso di $u$ è semplicemente il numero di elementi in $C(u)$ fratto il numero totale di nodi.

$$= \sum_{v \in U} \frac{|C(u)|}{n} = \sum_{v \in U} \frac{1 + d(u)}{n} $$
Siccome $d(u) \geq \delta(G)$ per definizione

$$\geq \sum_{v \in U} \frac{1 + \delta(G)}{n}$$ Ci siamo liberati di $v$ all'interno della sommatoria, quindi

$$= r \frac{1 + \delta(G)}{n}$$
Possiamo concludere che al termine dell'iterazione rimangono al massimo $$r - r\frac{1+\delta(G)}{n} = r(1- \frac{1 + \delta(G)}{n})$$ nodi. Notiamo che, partendo dall'inizio, dopo $m$ iterazioni rimarranno

$$n(1-\frac{1 +\delta(G)}{n}) \dots (1-\frac{1 +\delta(G)}{n})$$

$$= n(1-\frac{1 +\delta(G)}{n})^m$$
nodi. Ci chiediamo ora quando $m$ è sufficiente affinché rimangano $\leq \frac{n}{1 + \delta(G)}$ vertici ancora da dominare. Ovvero

$$n(1-\frac{1 +\delta(G)}{n})^m \leq \frac{n}{1 + \delta(G)}$$
Applichiamo la nota disequazione 

$$1-x \leq e^{-x} \; \forall x \in \mathbb{R}$$


\trimbox{1.75cm 0cm 0cm -0.5cm}{
\begin{tikzpicture}[domain=-1:2]
           \begin{axis} [xlabel = x, ylabel = y, axis lines=center, ymin = -1,xmax = 2.5, ymax = 3,  yticklabel=\empty, xticklabel = \empty, clip = false]           
           \addplot[color=yellow,samples=100,smooth, thick] {1-x}node[below left, pos = 0.1]{$1-x$};
           \addplot[color=purple,samples=100,smooth, thick] {e^(-x)}node[above right, pos = 0.1]{$e^{-x}$};

            \end{axis}
\end{tikzpicture}
}


$$n(1-\frac{1 +\delta(G)}{n})^m $$

$$\leq n \cdot exp(-\frac{1 + \delta(G)}{n}m)$$ Usiamo $exp$ per evitare di avere $e$ con esponente una frazione, ma è la stessa cosa.

$$n \cdot exp(-\frac{1 + \delta(G)}{n}m)\leq \frac{1}{1 + \delta(G)}$$ Applichiamo la funzione logaritmo su ambo i lati

$$- \frac{1 + \delta(G)}{n} m \leq -\ln(1+ \delta(G)) $$

$$m \geq  n \frac{\ln(1 + \delta(G))}{1 + \delta(G)}$$
Assumiamo di essere arrivati all'iterazione $m = n \frac{\ln(1 + \delta(G))}{1 + \delta(G)}$. Sia $s$ il numero di vertici ancora da dominare dopo $m$ passi.  Siccome $m$ è la risposta alla domanda che ci siamo posti prima, vale che

$$s \leq \frac{n}{1 + \delta(G)}$$ 
Nel caso peggiore l'algoritmo sceglierà altri $s$ vertici per completare la costruzione dell'insieme dominante. Ma allora la cardinalità dell'insieme finale sarà 

$$\gamma(G) \leq |S| \leq m + s$$

$$\leq n \frac{\ln(1 + \delta(G))}{1 + \delta(G)} +  \frac{n}{1 + \delta(G)}$$ Sapendo che $n = |V|$ e rigirando l'equazione

$$\gamma(G) \frac{1 + \delta(G)}{1 + \ln{(1 + \delta(G))}} \leq |V|$$

\end{dimo}

\section{Grafi casuali}
Un \textbf{modello generativo} per grafi è una distribuzione di probabilità su tutti i grafi di un certo ordine. Il più famoso è il modello di \textbf{Erd\"{o}s-Rényi}. Indichiamo con $\mathscr{G}(n,p) $ la distribuzione di probabilità su grafi di ordine $n$. Dato il grafo $G = (V,E)$, l'arco $\{i,j\} \in [V ]^2$ è tale che $\{i,j\} \in E$ con probabilità $p$. L'estrazione è indipendente  $\forall i \neq j$. Quindi 

$$\mathds{I}\{\{i,j\} \in E\} \sim Bern(p)$$
\begin{itemize}
    \item Se $p = 0$ allora il grafo ottenuto ha sempre $0$ lati.
    \item Se $p = 1$ allora il grafo ottenuto ha sempre tutti i lati in $[V]^2$.
    \item Se $0 < p < 1$ allora ogni grafo di ordine $n$ ha probabilità $> 0$ di essere estratto da $\mathscr{G}(n,p)$
\end{itemize}

\noindent
Notiamo che $p$ regola la densità del grafo.
La distribuzione $\mathscr{G}(n,\frac{1}{2})$ è uniforme su tutti i grafi di ordine $n$. 
Sia $H = (V,E)$ un grafo di ordine $n$. La probabilità di estrarre $H$ è 

$$ P(H) = p^{|E|} (1-p)^{\binom{n}{2} - |E|}$$ 
Invece la probabilità di estrarre un grafo con $k$ lati è 

$$P(|E| = k) = \sum_{\substack{ E' \in [V]^2 \\ \land |E'| = k}} p^k (1-p)^{\binom{n}{2} - k}$$

$$= \binom{|[V]^2|}{k}p^k (1-p)^{\binom{n}{2} - k}$$

$$= \binom{\binom{n}{2}}{k}p^k (1-p)^{\binom{n}{2} - k}$$
ed è una binomiale di parametri $\binom{n}{2}$ e $p$. Il valore atteso è $$\va[|E|] = \binom{n}{2}p$$ ovvero il prodotto tra i parametri della distribuzione.
Siccome a volte la dimostrazione costruttiva , usiamo il modello di Erd\"{o}s-Rényi per dimostrare delle proprietà attraverso il \textbf{metodo probabilistico}. Ovvero, dato lo spazio di probabilità definito dalla tripla

 $$(\Omega,F,P)$$
dove $\Omega$ è lo spazio campione (contiene gli eventi elementari), $F$ lo spazio degli eventi ($F \subseteq \Omega$) e $P$ la misura (distribuzione) di probabilità. Per esempio, sia $\Omega$ l'insieme dei grafi di ordine $n$. Ci chiediamo se ci siano dei grafi bipartiti.  Sia $A$ l'insieme dei grafi bipartiti di ordine $n$ ($A \subseteq \Omega $) ci chiediamo

$$\exists \; \omega \in \Omega \;t.c.\; \omega \in A?$$

\noindent
Se $A \neq \varnothing$  allora esiste. Questo equivale a chiedersi $P(A) > 0$, che implica $\exists \omega \in \Omega$ che soddisfa la proprietà (notare che non è una 
co-implicazio-ne!).


\chapter{Settima lezione}

\section{Strumenti di probabilità}
Introduciamo due importanti disequazioni che saranno utili per diverse dimostrazioni usando il metodo probabilistico. Sia $(\Omega,P)$ uno spazio di probabilità e siano $E_1,\dots,E_n$ degli eventi qualsiasi. Per la \textbf{regola dell'unione} vale la disuguaglianza

$$P(E_1 \cup \dots \cup E_n) \leq \sum_{i = 1}^n P(E_i) $$
Graficamente possiamo convincerci della correttezza della disequazione.

\disegna{
         \node[squarednode,minimum width=5cm,minimum height = 4cm
        ](A3) at (0,2)[]{};
       \node[] at (-2.2, 3.75) {$\Omega$};
       \node[] at (0, 0.5) {$E_1$};
       \node[] at (-1.55,2.70) {$E_2$};
       \node[] at (1.55,2.70) {$E_3$};
        
      \draw (90:1.75cm) circle (1.5cm) node[text=black,below, pos =0.8] {};

      \draw (110:2.5cm) circle (1.5cm);
      \draw (70:2.5cm) circle (1.5cm);

}

\noindent 
Le zone che sono in comune, sommando le probabilità dei singoli $E_i$, vengono contate più volte, quindi è ovvio che la sommatoria sia maggiore (o al massimo uguale) alla probabilità dell'unione.
Data una variabile aleatoria $X$ non negativa, $\forall a > 0$ vale
$$P(X \geq a ) \leq \frac{\va[X]}{a}$$
Questa disuguaglianza è detta \textbf{disuguaglianza di Markov}. La dimostrazione è omessa.

\section{Proprietà grafi}

\begin{fatto}
    $\forall n \geq 4$ e $\forall K \geq 2\log{n}$ $\; \exists G$ di ordine $n$ tale che $\alpha(G) < k$ e $\omega(G) < k$.
\end{fatto}

\noindent
   Notiamo che le due proprietà sembrano quasi contrastanti. Un insieme di indipendenza grande preclude una grande clique, e viceversa.

\begin{dimo}
    Consideriamo $G \sim \mathscr{G}(n,\frac{1}{2})$. Qual è la probabilità che $U \subset V$, con $|U| = k$, sia indipendente in $G$? $(1 - \frac{1}{2})^{\binom{k}{2}}$. Quindi,

        
        $$P(\alpha(G) > k )$$
        \begin{multline*}
            = P(\exists U \subseteq V \; \text{t.c.} \;  |U| = k,\\\; \text{indipendente in }\; G)
        \end{multline*}

        $$= P(\bigcup_{\substack{U \subseteq V \\ |U| = k}} \{\text{U è indipendente in G}\}) $$

        $$\leq \sum_{\substack{U \in V \\ |V| = k}} P(\text{U è indipendente in G})$$
        $$= \sum_{\substack{U \in V \\ |V| = k}} 2^{-\binom{k}{2}} =  \binom{n}{k} 2^{-\binom{k}{2}}$$
        Usiamo ora il fatto che 

        $$\binom{n}{k} \leq (\frac{n}{2})^k$$
        per $4 \leq k \leq n$. Quindi:

        $$\binom{n}{k} 2^{-\binom{k}{2}} \leq (\frac{n}{2})^k \; 2^{-\frac{k(k-1)}{2}} $$
        Sfruttando le proprietà dei logaritmi scriviamo

        $$2^{\log_2{(\frac{n}{2})^k}}  2^{-\frac{k(k-1)}{2}} = 2^{\log_2{(\frac{n}{2})^k} - \frac{k(k-1)}{2} }$$

        $$= 2^{k(\log_2{n} - 1) - \frac{k(k-1)}{2}}$$
        Con la condizione che $k \geq 2\log_2{n}$
        $$\geq 2^{\frac{k^2}{2} - k - \frac{k(k-1)}{2}} = 2^{-\frac{k}{2}}$$
        Siccome $k \geq 4$, allora 

        $$2^{-\frac{k}{2}} < \frac{1}{2}$$
        Dato $U \subseteq V$ con $|U| = k$ la probabilità che $U$ formi una clique in $G$ è $2^{-\frac{k}{2}}$. Rifacendo la stessa derivazione di prima arriviamo a dire che $P(\omega(G) \geq k) < \frac{1}{2}$. Quindi possiamo affermare

        $$P(\alpha(G) < k, \omega(G) < k) $$
        $$= 1 - P(\alpha(G) \geq k \; \lor \; \omega(G) \geq k )$$

        $$\geq 1 - P(\alpha(G) \geq k) - P(\omega(G) \geq k)$$

        $$> 1 - \frac{1}{2} - \frac{1}{2} = 0$$
        Abbiamo dimostrato che  $P(\alpha(G) < k, \omega(G) < k) > 0$, questo implica che debba esistere un grafo $G$ di ordine $n$ tale che $\alpha(G) < k$ e $\omega(G) < k$.
\end{dimo}

\noindent 
Discutiamo un'altra proprietà che, similmente alla precedente, sembra essere contrastante.

\begin{teo} \textbf{Teorema di Erdos}. $\forall \; k \; \exists  \; G$ tale che 

$$g(G) > k \land \chi(G) > k$$
    
\end{teo}

\noindent
Prima di dimostrare il teorema introduciamo un lemma utile alla sua dimostrazione.

\begin{lemma}
    Il valore atteso del numero di cicli di lunghezza $k$ in $G \sim \mathscr{G}(k,n)$ è $$\frac{n(n-1)\dots(n-k+1)}{2k} p^k$$
\end{lemma}
\begin{dimo}
    Dimostriamo il lemma precedente.
    Sia $C_k$ l'insieme con tutti i cicli possibili di lunghezza $k$ su $n$ vertici. Ci chiediamo quanti siano. Un ciclo è determinato dai vertici che ne fanno parte. Il numero di modi per scegliere $k$ vertici è 
    $$n (n-1) \dots (n-k+1)$$
    Dobbiamo però considerare che in questo modo contiamo $k$ volte ogni ciclo per il fatto che cambiamo solamente l'ordine dei nodi, e un addizionale $2$ volte per ogni verso. Quindi 

    $$|C_k| = \frac{n (n-1) \dots (n-k+1)}{2k}$$
    Dove dividiamo per $2k$ perché ci sono esattamente $2k$ sequenze che corrispondono allo stesso ciclo.
    Sia $C \in C_k$, ci chiediamo  qual è la probabilità che $G$ contenga $C$ ? $p^k$, perché ogni arco tra i $k$ nodi deve essere estratto, gli altri non ci interessa cosa succede.  Indichiamo con $N_k(G)$ il numero di cicli di lunghezza $k$ in G, allora

    $$\va[N_k(G)] = \sum_{C \in C_k} P(\text{G contiene C})$$
    $$= \sum_{C \in C_k} p^k$$
    La sommatoria diventa indipendente da $C$

    $$= |C_k| \cdot p^k$$
    $$= \frac{n (n-1) \dots (n-k+1)}{2k} p^k$$
\end{dimo}


\end{document}
